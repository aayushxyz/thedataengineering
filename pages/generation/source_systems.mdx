# Source Systems in Data Engineering

In the data engineering lifecycle, the first stage is data generation, which involves identifying and understanding the various source systems that produce data. This article will explore what data is, how it is created, and the different types of source systems commonly encountered in data engineering.

## What is Data?

Data refers to raw, unorganized facts and figures that are collected and stored for processing and analysis. It can be structured, semi-structured, or unstructured and comes in various formats such as numbers, text, images, audio, and video.

## How is Data Created?

Data is created through various processes and interactions, including:

Data creation occurs through:
- User Interactions: When users interact with applications, websites, or devices, they generate data through actions like filling forms, making purchases, or clicking links.
- Automated Systems: Machines, sensors, and IoT devices continuously generate data through measurements, logs, and monitoring activities.
- Business Transactions: Daily business operations create data through sales, inventory management, customer interactions, and other processes.

## Source Systems

### Files

Files are a common source of data and can include:

- CSV (Comma-Separated Values) files: These are plain text files that store tabular data, where each line represents a record and each column is separated by a comma.
- JSON (JavaScript Object Notation) files: These are lightweight, text-based files that store structured data in a key-value format, making them easy to read and parse.
- XML (eXtensible Markup Language) files: These are self-descriptive files that use tags to define elements and store hierarchical data.

### APIs

APIs (Application Programming Interfaces) allow different software applications to communicate and exchange data. They provide a standardized way to access and retrieve data from various sources, such as web services, databases, or other applications. APIs can return data in formats like JSON or XML, making it easy to integrate with data engineering pipelines.

### Application Databases (OLTP)

OLTP (Online Transaction Processing) databases are designed to handle a large number of short, fast transactions in real-time. These databases are optimized for inserting, updating, and deleting data quickly and efficiently. Examples of OLTP databases include MySQL, PostgreSQL, and Oracle Database. Data engineers often extract data from OLTP databases for further processing and analysis.

### OLAP (Online Analytical Processing)

OLAP databases are optimized for complex queries and analysis of large volumes of historical data. They are designed to support business intelligence and decision-making processes. OLAP databases store data in a multidimensional structure, allowing for fast retrieval and analysis of data from different perspectives. Examples of OLAP databases include Apache Kylin, Microsoft Analysis Services, and Oracle Essbase.

### Change Data Capture (CDC)

Change Data Capture is a technique used to identify and capture changes made to a database in real-time or near-real-time. CDC allows data engineers to track and replicate data changes from source systems to target systems, ensuring data consistency and enabling real-time data integration. CDC can be implemented using various methods, such as database triggers, log-based CDC, or query-based CDC.

### Logs

Logs are files that record events, activities, and other relevant information generated by applications, systems, or devices. They provide valuable insights into system behavior, performance, and issues. Data engineers can collect and analyze log data to monitor systems, detect anomalies, and gain insights. Common types of logs include:

- Application logs: These logs capture events and errors generated by software applications, helping developers and data engineers identify and resolve issues.
- Access logs: These logs record information about user access and activities within a system, which can be used for auditing and security purposes.
- System logs: These logs capture events and messages generated by operating systems, providing information about system health, performance, and potential issues.

### Database Logs

Database logs are files that record all transactions and modifications made to a database. They are essential for ensuring data integrity, recovery, and replication. Data engineers can use database logs to:

- Monitor database activity and performance
- Implement change data capture (CDC) to replicate data changes to other systems
- Perform point-in-time recovery in case of database failures or errors

### Messages and Streams

Messages and streams are data sources that continuously generate data in real-time. They are commonly used in event-driven architectures and real-time data processing scenarios. Examples include:

- Apache Kafka: A distributed streaming platform that allows for the publishing, subscribing, and processing of real-time data streams.
- Apache Pulsar: An open-source distributed pub-sub messaging system designed for high-performance data streaming and messaging.
- Amazon Kinesis: A fully managed service for real-time data streaming and processing, allowing for the collection, processing, and analysis of large volumes of data in real-time.

## Conclusion

Understanding the various source systems and how data is created is crucial for data engineers. By identifying and integrating data from different sources, such as files, APIs, databases, logs, and streams, data engineers can build robust data pipelines and enable data-driven decision-making within organizations. Effective management and processing of data from these source systems lay the foundation for successful data engineering projects.